\section{Conclusions and Future Work}
\label{sec:conclusion}
In the end there is no obvious winner between static and dynamic analysis.
As the research shows, both approaches have their own advantages and drawbacks in terms of accuracy, runtime and ease of use.
While static analysis slightly overapproximates, techniques using more information about the program reduce this problem, and analysis times can also be reduced by compromising a bit on accuracy.
And although dynamic analysis usually underapproximates, sometimes this effect may be beneficial and should not be overlooked.

To summarize, this research explored the area of system call sandboxing, comparing various implementations in the area. To compare the approaches, an experiment was set up and carried out, after which the results such as accuracy and runtime were collected. To finalize the research reflects upon the results aiming to answer the research questions it set out to investigate.

A dynamic analysis based implementation was proposed in order to evaluate how well a purely dynamic analysis based solution would perform, since this approach is less popular in the field.
The results show that such an approach is faster compared to other solutions, and blocks more system calls, although at the cost of accuracy.
A key problem of the approach is the underestimation of the set of required system calls, which relies on there being a sufficient amount of test cases that explore many possible program state.
A strong positive of this approach is the ability to create custom system call filters based on usage pattern, thus achieving more security.

Static analysis based tools, namely sysfilter, Confine and chestnut, were set up and tested.
The results show that each implementation blocks a different number of system calls and does so with varying analysis time.
The research discusses the potentials to speed up analysis time and looks at the advantages and drawbacks of these tools, also taking into account the ease of setup and usability.
A key problem of these tools is the difficulty to setup and maintain, such as switching distribution or upgrading a compiler or library.
A strong positive of these tools is that they are able to generate a relatively precise set of system calls to filter, independent of the given application.

Additionally the multi phase model of execution was investigated in both the static and dynamic analysis context.
The research shows that static and dynamic analysis have the same drawbacks and advantages as in the case for a single phase execution model.
Furthermore, based on the results the multi phase execution model is more effective compared to the single phase counterpart, and can be deployed even on applications, which do not follow the general life cycle of server programs.
A key problem of this approach is the need to identify the optimal transition points.
A strong positive is the ability to have an even more restrictive filter for certain parts of the execution.

It is possible to perform more research in this area by improving techniques based on this research.
Based on the results, approaches which precompute and cache call graphs and other results for commonly used libraries tend to spend less time analysing, such as in the case of Confine or chestnut.
Furthermore, the research shows that incorporating all CPU cores to do the analysis can be beneficial in reducing analysis times.

To improve multi phase execution the research highlights 2 core ideas.
First, defining transition points on the instruction level, which although cumbersome, offers the possibility to split large functions into phases, allowing the technique to be applied to programs such as \textit{ls}, which would not be considered multiple phase.
Second, the ability to define multiple transition points as opposed to one, although not investigated in this research, should allow for greater flexibility and even more precise filters.

Additionally, this research did not focus on to what extent the programs remain functional after applying the given filters, due to lack of time.
However to increase confidence in these solutions, and to find potential problems in the various techniques it would be important to investigate this aspect as well.
